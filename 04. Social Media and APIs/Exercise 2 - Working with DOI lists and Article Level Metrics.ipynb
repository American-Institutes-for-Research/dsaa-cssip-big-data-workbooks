{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - Working with DOI lists and Article Level Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will cover how to collect DOIs and Article Level Metrics(ALM) through API as well as some related analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Part A: Collecting DOIs](#Part-A:-Collecting-DOIs)\n",
    "- [Part B: Collecting and analysing ALM Data](#Part-B:-Collecting-and-analysing-ALM-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the required packages before the start of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "#os.environ['PLOS_API_KEY'] = 'user api key'\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../modules/orcid-python\")\n",
    "sys.path.append(\"../modules/pyalm\")\n",
    "\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import orcid\n",
    "import pyalm.pyalm as pyalm\n",
    "sys.path.append(\"./modules/pyalm/pyalm\")\n",
    "import utilities.plossearch as search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Collecting DOIs\n",
    "\n",
    "Back to [Table of Contents](#Table-of-Contents).\n",
    "\n",
    "The first part this exercise will show collecting DOIs from a different source, a publisher API. Here we are using the PLOS Search API as an example because the PLOS Lagotto instance has the most information on article level metrics as discussed in the class.\n",
    "\n",
    "We will first show an example of using the provided API wrapper and then you will use this to gather Article Level Metrics information on some authors from Caltech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initiate and populate a query object\n",
    "query = search.Request('author_affiliate:\"California Institute of Technology\"')\n",
    "\n",
    "# Initiate the actual API call and get some results\n",
    "response = query.get()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives 220 DOI's found at PLOS which match the affiliation term \"California Institute of Technology\". You might want to change the search term to see if there are other articles, perhaps listed under Caltech or other variations of the name.\n",
    "\n",
    "This search matches the terms that you will find in the Advanced Search functionality on the PLOS website: http://www.plosone.org/search/advanced?noSearchFlag so you can use that search form to construct a more advanced search and then use it with the function above. For instance a more complex search for Caltech might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Initiate and populate a query object\n",
    "query = search.Request(\"\"\"\n",
    "    author_affiliate:\"California Institute of Technology\"\n",
    "    OR\n",
    "    author_affiliate:\"Caltech\"\n",
    "                       \"\"\")\n",
    "\n",
    "# Initiate the actual API call and get some results\n",
    "caltech = query.get()\n",
    "\n",
    "# Count the number of documents returned.\n",
    "len( caltech['response']['docs'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Construct a search that looks for papers by either authors Martin Karplus, Robert Grubbs or Eric Betzig.  Store the results of your call to `query.get()` in a variable named `response`.  Your query should retrieve two articles.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "A-search-BGK",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "# Initiate and populate a query object\n",
    "query = search.Request(\"\"\"\n",
    "    author:\"Eric Betzig\"\n",
    "    OR\n",
    "    author:\"Robert Grubbs\"\n",
    "    OR\n",
    "    author:\"Martin Karplus\"\n",
    "                       \"\"\")\n",
    "\n",
    "# Initiate the actual API call and get some results\n",
    "response = query.get()\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "# Count documents returned.\n",
    "print( \"Document count: \" + str( len( response['response']['docs'] ) ) )\n",
    "\n",
    "# Output documents returned.\n",
    "print( \"Result: \" + str( response['response']['docs'] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "A-search-BGK-test-len",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test - should be two documents.\n",
    "assert len( response['response']['docs'] ) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "A-search-BGK-test-DOI",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# could also check the DOIs of the two items.\n",
    "doi_list = []\n",
    "for current_item in response['response']['docs']:\n",
    "    \n",
    "    current_doi = current_item[ 'doi' ]\n",
    "    doi_list.append( current_doi )\n",
    "    \n",
    "#-- END loop over documents. --#\n",
    "\n",
    "# get DOI 1 and 2\n",
    "doi_1 = doi_list[ 0 ][ 0 ]\n",
    "doi_2 = doi_list[ 1 ][ 0 ]\n",
    "\n",
    "# are they right?\n",
    "assert doi_1.lower() == '10.1371/journal.pbio.1000137'\n",
    "assert doi_2.lower() == '10.1371/journal.pbio.0040144'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Collecting and analysing ALM Data\n",
    "\n",
    "Back to [Table of Contents](#Table-of-Contents)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Based on the example notebooks obtain Article Level Metrics data on these two articles from the PLOS ALM API (`pyalm`). Note that the ALM API wrapper can accept a list of DOIs as well as a single DOI. You will need to construct a list of the two DOIs to pass to the `pyalm.get_alm` function (stored in the variable `dois`).  Then, obtain the number of EuropePubmedCentral citations for all the articles.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to configure the API URL as per the notebook example\n",
    "pyalm.config.APIS = { \n",
    "    'plos' : {'url': 'http://alm.plos.org/api/v5/articles'},\n",
    "    'det'  : {'url' : 'http://det.labs.crossref.org/api/v5/articles'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "B-ALM-doi_list",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Make a list of the DOI values present in the response from part A.\n",
    "dois = []\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# traditional list creation\n",
    "for current_item in response['response']['docs']:\n",
    "    \n",
    "    current_doi = current_item[ 'doi' ][ 0 ]\n",
    "    dois.append( current_doi )\n",
    "    \n",
    "#-- END loop over documents. --#\n",
    "\n",
    "# OR - list comprehension\n",
    "#dois = [ doc.get('doi')[0] for doc in response.get('response').get('docs') ]\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print( \"Found \" + str( len( dois ) ) + \" DOIs: \" + str( dois ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "B-ALM-doi_list-test_len",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test - should be two DOIs\n",
    "assert len( dois ) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "B-ALM-doi_list-test_values",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test - get DOI 1 and 2\n",
    "doi_1 = dois[ 0 ]\n",
    "doi_2 = dois[ 1 ]\n",
    "\n",
    "# are they what we expect?\n",
    "assert doi_1.lower() == '10.1371/journal.pbio.1000137'\n",
    "assert doi_2.lower() == '10.1371/journal.pbio.0040144'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "B-ALM-get_data",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Use the pyalm.get_alm() method to retrieve PLOS Article Level Metrics for the\n",
    "#    two articles.  Store the results in a variable named \"plos_alm\".\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "plos_alm = pyalm.get_alm(dois, info='detail', instance='plos')\n",
    "### END SOLUTION\n",
    "\n",
    "print( plos_alm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "B-ALM-get_data-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test - should be a dictionary\n",
    "assert type( plos_alm ) == dict # should be dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "B-ALM-EuPMC-cites",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# From the PLOS ALM data, get the title and number of EuPMC citations for\n",
    "#    each article - create a list of tuples called \"cites\" as follows:\n",
    "#    [('title1', citations), ('title2', citations)]\n",
    "\n",
    "cites = []\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "for article in plos_alm['articles']:\n",
    "\n",
    "    cites.append( ( article.title, article.sources['pmceurope'].metrics.total ) )\n",
    "    \n",
    "### END SOLUTION\n",
    "\n",
    "# print out cites\n",
    "print( \"cites per article: \" + str( cites ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "B-ALM-EuPMC-cites-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test - see if cites is as we expect it to be.\n",
    "assert cites[0] == (u'Self-Organization of the <i>Escherichia coli</i> Chemotaxis Network Imaged with Super-Resolution Light Microscopy', 108)\n",
    "assert cites[1] == (u'A Src-Like Inactive Conformation in the Abl Tyrosine Kinase Domain', 91)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    For the papers returned from a search for the first 50 articles affiliated with California Institute of Technology above (stored in the variable `caltech`), retrieve the PLOS Article Level Metrics for each article, then output the number of EuropePMC citations, Facebook posts and Tweets per article. It may take some time for the API to return results for 50 articles.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "B-ALM-caldois_list",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of the first 50 DOIs stored in variable \"caldois\".\n",
    "caldois = []\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "caldois = [doc['doi'][0] for doc in caltech['response']['docs']][0:50]\n",
    "### END SOLUTION\n",
    "\n",
    "print( \"caldois list:\" )\n",
    "doi_counter = 0\n",
    "for current_doi in caldois:\n",
    "    \n",
    "    doi_counter += 1\n",
    "    print( \"- DOI \" + str( doi_counter ) + \": \" + current_doi )\n",
    "    \n",
    "#-- END loop over DOIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "B-ALM-caldois_list-test_len",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test - should be 50 DOIs.\n",
    "assert len( caldois ) == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "B-ALM-cal_alm",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# get the ALMs from PLOS API for these articles and store them in \"cal_alm\".\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "cal_alm = pyalm.get_alm(caldois, info='detail', instance='plos')\n",
    "### END SOLUTION\n",
    "\n",
    "print( \"Got back \" + str( len( cal_alm[ 'articles' ] ) ) + \" ALM records.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "B-ALM-cal_alm-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test - should be a dictionary\n",
    "assert type( cal_alm ) == dict # should be dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "B-ALM-cal_alm-results",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Construct a list of tuples in a variable named \"results\" formatted as follows:\n",
    "# [\n",
    "#     ('title1','pmceurope1','facebook1','twitter1'),\n",
    "#     ('title2','pmceurope2','facebook2','twitter2'),\n",
    "#     ...\n",
    "# ]\n",
    "results = []\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "for article in cal_alm['articles']:\n",
    "    results.append((article.title, \n",
    "                   article.sources['pmceurope'].metrics.total,\n",
    "                   article.sources['facebook'].metrics.total,\n",
    "                   article.sources['twitter'].metrics.total))\n",
    "### END SOLUTION\n",
    "\n",
    "print( \"results list:\" )\n",
    "result_counter = 0\n",
    "for current_result in results:\n",
    "    \n",
    "    result_counter += 1\n",
    "    print( \"- result \" + str( result_counter ) + \": \" + str( current_result ) )\n",
    "    \n",
    "#-- END loop over results. --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "B-ALM-cal_alm-results-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test - should be 50 results\n",
    "assert len(results) == 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Make a list called `common_tweeters` that contains the twitter account handles for anyone who tweeted about more than one article.  To do this, first find articles with one or more tweets and store them in a list named `tweeted`.  Then, make a set of the unique account names of the users who tweeted about one or more articles, and store this set in a variable named `unique_accounts`.  Finally, identify accounts that tweeted more than one article, store the list of the twitter handles of these accounts in variable `common_tweeters`, then output the common tweeters.\n",
    "<br />\n",
    "<br />\n",
    "Note that some accounts might tweet about the same article twice. We are only interested in cases where the same account is tweeting about more than one article. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "B-tweet-articles",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Find articles that were tweeted at least once.  Store them in list \"tweeted\".\n",
    "tweeted = []\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "for article in cal_alm['articles']:\n",
    "    if article.sources['twitter'].metrics.total != 0:\n",
    "        tweeted.append(article)\n",
    "### END SOLUTION\n",
    "\n",
    "print( \"Tweeted articles: \" + str( len( tweeted ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "B-tweet-articles-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test - should be at least 10 tweeted articles.\n",
    "assert len(tweeted) > 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "B-tweet-users",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Now obtain all the account names. Look at the example notebook\n",
    "#    \"3. Working in practice.ipynb\" for how to get this information.\n",
    "unique_accounts = set()\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "for article in tweeted:\n",
    "    for tweet in article.sources['twitter'].events:\n",
    "        unique_accounts.add(tweet['event']['user'])\n",
    "        \n",
    "### END SOLUTION\n",
    "\n",
    "print( \"Unique Account Count: \" + str( len(unique_accounts) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "B-tweet-common_tweeters",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Now check whether each twitter account tweeted about more than one article.\n",
    "#    This requires a little care and attention.  Store the handle of each twitter\n",
    "#    user who tweeted about more than one article in a list in \"common_tweeters\".\n",
    "common_tweeters = []\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "for account in unique_accounts:\n",
    "    count = 0\n",
    "    for article in tweeted:\n",
    "        tweeters = [tweet['event']['user'] for tweet in article.sources['twitter'].events]\n",
    "        if account in tweeters:\n",
    "            count+=1\n",
    "            \n",
    "    if count > 1:\n",
    "        common_tweeters.append(account)\n",
    "### END SOLUTION\n",
    "\n",
    "print( \"Found \" + str( len( common_tweeters ) ) + \" common tweeters:\" )\n",
    "print( common_tweeters )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "B-tweet-common_tweeters-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test - should be at least one common tweeter\n",
    "assert common_tweeters != []"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
